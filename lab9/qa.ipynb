{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.078487Z",
     "start_time": "2025-01-17T01:08:00.269265Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score\n",
    "import tqdm\n",
    "\n",
    "from evaluate import load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdda294e8c32f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dee6ae16050fe4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.083905Z",
     "start_time": "2025-01-17T01:08:03.079523Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "('1', 'Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?')\n"
     ]
    }
   ],
   "source": [
    "# laod questions\n",
    "questions_dict = {}\n",
    "with open(\"questions.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        row = json.loads(line)\n",
    "        questions_dict[row['_id']] = row['text']\n",
    "print(\"Questions:\")\n",
    "print(next(iter(questions_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5245986e469971bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.087638Z",
     "start_time": "2025-01-17T01:08:03.084461Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers:\n",
      "('1', 'Tak, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3.')\n"
     ]
    }
   ],
   "source": [
    "# laod answears\n",
    "answears_dict = {}\n",
    "with open(\"answers.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        row = json.loads(line)\n",
    "        answears_dict[row['question-id']] = row['answer']\n",
    "print(\"answers:\")\n",
    "print(next(iter(answears_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8371b615e5af4fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.223831Z",
     "start_time": "2025-01-17T01:08:03.088085Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages (context):\n",
      "('2004_2387_1', 'Art. 1. Wyraża się zgodę na dokonanie przez Prezydenta Rzeczypospolitej Polskiej ratyfikacji Konwencji o pozbawianiu uprawnień do kierowania pojazdami, sporządzonej w Luksemburgu dnia 17 czerwca 1998 r.')\n"
     ]
    }
   ],
   "source": [
    "# laod passages and titles\n",
    "passages_dict = {}\n",
    "with open(\"passages.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        row = json.loads(line)\n",
    "        passages_dict[row['_id']] = row['text']\n",
    "print(\"Passages (context):\")\n",
    "print(next(iter(passages_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86110255dc835aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.870768Z",
     "start_time": "2025-01-17T01:08:03.225316Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets:\n",
    "# train dataset (Poquad)\n",
    "\n",
    "id_ = 0\n",
    "train_data = []\n",
    "with open('poquad-train.json', \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        for line in data['data']:\n",
    "            for paragraph in line['paragraphs']:\n",
    "                context = paragraph['context']\n",
    "                for qa in paragraph['qas']:\n",
    "                    if not(qa['is_impossible']):\n",
    "                        question = qa['question']\n",
    "                        for ans in qa['answers']:\n",
    "                            answear = {\"text\": [ans['generative_answer']]}\n",
    "                            train_data.append({\n",
    "                                \"id\" : id_,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"answers\": answear,\n",
    "                            })\n",
    "                            id_ += 1\n",
    "train_dataset = Dataset.from_list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d88f236d7b3c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.935697Z",
     "start_time": "2025-01-17T01:08:03.871449Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Validation dataset (Poquad)\n",
    "\n",
    "id_ = 0\n",
    "val_data = []\n",
    "with open('poquad-dev.json', \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        for line in data['data']:\n",
    "            for paragraph in line['paragraphs']:\n",
    "                context = paragraph['context']\n",
    "                for qa in paragraph['qas']:\n",
    "                    if not(qa['is_impossible']):\n",
    "                        question = qa['question']\n",
    "                        for ans in qa['answers']:\n",
    "                            answear = {\"text\": [ans['generative_answer']]}\n",
    "                            val_data.append({\n",
    "                                \"id\" : id_,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"answers\": answear,\n",
    "                            })\n",
    "                            id_ += 1\n",
    "val_dataset = Dataset.from_list(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c2c940c1ef6606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.940745Z",
     "start_time": "2025-01-17T01:08:03.936613Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'context': 'Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.',\n",
       " 'question': 'Czym są pisma rabiniczne?',\n",
       " 'answers': {'text': ['kompilacją poglądów różnych rabinów na określony temat']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05ac10ed3c3907e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.954115Z",
     "start_time": "2025-01-17T01:08:03.941477Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'context': 'Art. 345. § 1. Żołnierz, który dopuszcza się czynnej napaści na przełożonego, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3. § 2. Jeżeli sprawca dopuszcza się czynnej napaści w związku z pełnieniem przez przełożonego obowiązków służbowych albo wspólnie z innymi żołnierzami lub w obecności zebranych żołnierzy, podlega karze pozbawienia wolności od 6 miesięcy do lat 8. § 3. Jeżeli sprawca czynu określonego w § 1 lub 2 używa broni, noża lub innego podobnie niebezpiecznego przedmiotu, podlega karze pozbawienia wolności od roku do lat 10. § 4. Karze przewidzianej w § 3 podlega sprawca czynu określonego w § 1 lub 2, jeżeli jego następstwem jest skutek określony w art. 156 lub 157 § 1.',\n",
       " 'question': 'Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?',\n",
       " 'answers': {'text': ['Tak, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3.']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test dataset (Legal questions)\n",
    "test_dataset = []\n",
    "with open(\"relevant.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        row = json.loads(line)\n",
    "        # take only those question that have answers and answear is not empty\n",
    "        if row['question-id'] not in answears_dict or len(answears_dict[row['question-id']]) == 0:\n",
    "            continue\n",
    "        test_dataset.append(\n",
    "            {\n",
    "                \"id\" : row['question-id'],\n",
    "                #'title': title_dict[row['passage-id']],\n",
    "                'context': passages_dict[row['passage-id']],\n",
    "                'question': questions_dict[row['question-id']],\n",
    "                'answers': {\"text\": [answears_dict[row['question-id']]]}\n",
    "            }\n",
    "        )\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d8c49f4303215b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:03.956440Z",
     "start_time": "2025-01-17T01:08:03.954746Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 46187\n",
      "Val set size: 5764\n",
      "Test set size: 593\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size:\", train_dataset.num_rows)\n",
    "print(\"Val set size:\", val_dataset.num_rows)\n",
    "print(\"Test set size:\", test_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26513005c071a381",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Model - T5 allegro - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bdd7876d1a5946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:04.957431Z",
     "start_time": "2025-01-17T01:08:03.957058Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allegro/plt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cb9445dddf1fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:04.962483Z",
     "start_time": "2025-01-17T01:08:04.958690Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # all inputs should have the same format. Pytanie + context in string.\n",
    "    inputs = [\"pytanie: \" + q + \"  context: \" + c for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
    "    targets = [ans[\"text\"][0] for ans in examples[\"answers\"]]\n",
    "    # Tokenizing inputs and targets\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # Tokenizing targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "    # Replace padding token id for labels to ignore index (-100) in loss computation\n",
    "    labels[\"input_ids\"] = [\n",
    "        [l if l != tokenizer.pad_token_id else -100 for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8896e0534f700415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.954070Z",
     "start_time": "2025-01-17T01:08:04.963063Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdb7d3a0524d978b38cb4137f10c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c659b0cb20429a9b6c80f2fb57cf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a22cf8e0ca540c2bad62fc81cead113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize all data:\n",
    "train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "val_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632354b6e33544f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Fine tuning polish T5 for - Abstractive Question Answearing\n",
    "\n",
    "Commented as it did not work on my pc (not enough resources, google collab refused to work :( but script works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30be70a88d4f3736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.956806Z",
     "start_time": "2025-01-17T01:08:41.955118Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./t5_qa_model\",\n",
    "#     eval_strategy=\"steps\",\n",
    "#     learning_rate=3e-5,\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     save_total_limit=1,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=500,\n",
    "#     save_steps=1000,\n",
    "#     report_to=\"none\",\n",
    "#     disable_tqdm=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a9085d91713ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.960955Z",
     "start_time": "2025-01-17T01:08:41.959666Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# if torch.backends.mps.is_available():\n",
    "#     print(\"Torch MPS availavle\")\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "#     print(\"running on CPU\")\n",
    "#     device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19a3e86e38e55fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.962549Z",
     "start_time": "2025-01-17T01:08:41.961405Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6d099f303da798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.964287Z",
     "start_time": "2025-01-17T01:08:41.963042Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821156e694bd7896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.966006Z",
     "start_time": "2025-01-17T01:08:41.964734Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0fdb9e02c574840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:41.968663Z",
     "start_time": "2025-01-17T01:08:41.966925Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#trainer.save_model(\"./t5_qa_model_saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53762036ee201ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Loading Polish T5 model fine-tuned on poquad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5f4d4f92541757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:43.218751Z",
     "start_time": "2025-01-17T01:08:41.969471Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apohllo/plt5-base-poquad\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"apohllo/plt5-base-poquad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2889052e65c30e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:43.552013Z",
     "start_time": "2025-01-17T01:08:43.219601Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f097b5251974f05b6f6bb8eaaf47b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize all data again to be sure it is tokenized with correct tokenizer and ready to model.\n",
    "# It should be the same models but to ensure myself:\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.map(preprocess_data, batched=True) # We don't use as the model is already fine-tuned\n",
    "# val_dataset = train_dataset.map(preprocess_data, batched=True) # We don't use as the model is already fine-tuned\n",
    "test_dataset = test_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f359921fd5259b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:43.557739Z",
     "start_time": "2025-01-17T01:08:43.554239Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 593\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b09569fea293b0d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:43.561066Z",
     "start_time": "2025-01-17T01:08:43.558326Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_model_preds(model, dataset):\n",
    "    preds = []\n",
    "    for i in tqdm.tqdm(range(len(dataset))):  # Iterujemy po każdym elemencie\n",
    "        input_ids = torch.tensor(dataset[i][\"input_ids\"]).unsqueeze(0).to('cpu')  # unsqueeze(0) dodaje wymiar batcha\n",
    "        attention_mask = torch.tensor(dataset[i][\"attention_mask\"]).unsqueeze(0).to('cpu')  # unsqueeze(0) dodaje wymiar batcha\n",
    "    \n",
    "        # Generowanie odpowiedzi\n",
    "        batch_generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=128,\n",
    "        )\n",
    "    \n",
    "        preds.append(batch_generated_ids)\n",
    "    \n",
    "    # Dekodowanie wyników\n",
    "    decoded_preds = []\n",
    "    for g in preds:\n",
    "        decoded_preds.append(tokenizer.decode(g[0], skip_special_tokens=True))\n",
    "    return decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d07556bb8d98acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:44.604627Z",
     "start_time": "2025-01-17T01:08:43.561670Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "exact_match = load(\"exact_match\")\n",
    "\n",
    "def compute_metrics(predictions, labels):\n",
    "    # get exact match using buil-in funtion in eval package\n",
    "    exac_m = exact_match.compute(predictions=predictions, references=labels)[\"exact_match\"]\n",
    "    \n",
    "    encoded_preds = tokenizer(\n",
    "        predictions,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    encoded_labels = tokenizer(\n",
    "        labels,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # Conversion needed to fit to sklearn API:\n",
    "    predictions_flat = encoded_preds.flatten().tolist()  # Convert to list of integers\n",
    "    labels_flat = encoded_labels.flatten().tolist()  # Convert to list of integers\n",
    "    predictions_flat = np.array(predictions_flat, dtype=np.int32)\n",
    "    labels_flat = np.array(labels_flat, dtype=np.int32)\n",
    "    # compute f1 from sklearn API\n",
    "    f1 = f1_score(labels_flat, predictions_flat, average='macro')\n",
    "\n",
    "    return exac_m, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85d372519433aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:08:44.607182Z",
     "start_time": "2025-01-17T01:08:44.605286Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_model_on_dataset(model, dataset):\n",
    "    labels_text = [answer[\"text\"][0] for answer in dataset[\"answers\"]]\n",
    "    \n",
    "    model_preds = get_model_preds(model, dataset)\n",
    "    em, f1 = compute_metrics(model_preds, labels_text)\n",
    "    return em, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3b52997b2f0de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Evaluation model on Val Dataset (Poquad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39324065fac21023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:12:44.843348Z",
     "start_time": "2025-01-17T01:08:44.607751Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [04:00<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 0.18043844856661045, F1: 0.13481808954883703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#subset = test_dataset.select(range(20))\n",
    "em, f1 = eval_model_on_dataset(model, test_dataset)\n",
    "print(f\"Exact Match: {em}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e384e377eb7ea3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Evaluation model on Test Dataset (Legal-Questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434adb819812bb13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:45:27.983017Z",
     "start_time": "2025-01-17T01:12:44.844789Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46187/46187 [13:32:38<00:00,  1.06s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 0.6042176369974235, F1: 0.5613763916810257\n"
     ]
    }
   ],
   "source": [
    "em, f1 = eval_model_on_dataset(model, val_dataset)\n",
    "print(f\"Exact Match: {em}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2f387c4a2d4e69f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:57:36.297990Z",
     "start_time": "2025-01-17T14:57:36.295265Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def analyze_answer(model, dataset_record, data):\n",
    "    pred = get_model_preds(model, dataset_record)\n",
    "    print(\"Context:\")\n",
    "    print(data['context'])\n",
    "    print(\"Question:\")\n",
    "    print(data['question'])\n",
    "    print(\"True answer:\")\n",
    "    print(data['answers']['text'])\n",
    "    print(\"predicted answer:\")\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace70e653d3c912",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Analyze of 10 examples from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c78e91d0cb72dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:57:37.613266Z",
     "start_time": "2025-01-17T14:57:37.031479Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 35. 1. Wartość rzeczowych składników majątku obrotowego, które utraciły swoje cechy użytkowe lub przydatność, oraz odpadów ustala się nie później niż na dzień bilansowy w cenach sprzedaży netto możliwych do uzyskania. 2. Wartość produktów gotowych i towarów, z wyjątkiem towarów używanych znajdujących się w punktach sprzedaży oraz towarów przewidzianych do wieloletniej sprzedaży, zmniejsza się stopniowo, uwzględniając utratę ich wartości rynkowej, przez okres nie dłuższy niż 5 lat, poczynając od roku obrotowego następującego po roku, w którym je zakupiono lub wytworzono. 3. Odpisy aktualizujące: 1) wartość rzeczowych składników majątku obrotowego, o których mowa w ust. 1 i 2, oraz wynikające z wyceny według cen sprzedaży netto zamiast według cen nabycia (zakupu) lub kosztów wytworzenia - zwiększają pozostałe koszty operacyjne, 2) wartość udziałów w innych jednostkach oraz długoterminowych papierów wartościowych (lokat) - obciążają koszty operacji finansowych; jeżeli w wyniku wzrostu kursów giełdowych ceny sprzedaży netto długoterminowych papierów wartościowych (lokat) są wyższe od cen, po których je nabyto, to długoterminowe papiery wartościowe (lokaty) wykazuje się według cen ich nabycia, odnosząc różnice między ich dotychczasową, niższą wyceną a wartością według cen nabycia na przychody z operacji finansowych.\n",
      "Question:\n",
      "Kiedy ustala się wartość majątku obrotowego, który stracił swoją przydatność?\n",
      "True answer:\n",
      "['Wartość rzeczowych składników majątku obrotowego, które utraciły swoje cechy użytkowe lub przydatność ustala się nie później niż na dzień bilansowy w cenach sprzedaży netto możliwych do uzyskania']\n",
      "predicted answer:\n",
      "['nie później niż na dzień bilansowy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [3]), test_dataset[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff31cbf87bdc1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Krótko, konkretnie i poprawnie, odpowiedz dobra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c42394ddde44374c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:59:15.534301Z",
     "start_time": "2025-01-17T14:59:14.882990Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 74. 1. Armator, który wykonuje rybołówstwo morskie w polskich obszarach morskich, z naruszeniem przepisów ustawy, podlega karze pieniężnej do wysokości 1 000 000 złotych. 2. Karze, o której mowa w ust. 1, podlega również armator statku o polskiej przynależności, który wykonuje rybołówstwo morskie poza polskimi obszarami morskimi, z naruszeniem przepisów ustawy lub postanowień umów międzynarodowych, których Rzeczpospolita Polska jest stroną. 3. Minister właściwy do spraw rolnictwa określi, w drodze rozporządzenia, wysokość kar pieniężnych za naruszenia, o których mowa w ust. 1 i 2, zróżnicowane w zależności od ich rodzaju i społecznej szkodliwości.\n",
      "Question:\n",
      "Jakiej karze podlega armator, który wykonuje rybołówstwo morskie w polskich obszarach morskich, z naruszeniem przepisów ustawy?\n",
      "True answer:\n",
      "['Podlega karze pieniężnej do wysokości 1 000 000 złotych']\n",
      "predicted answer:\n",
      "['pieniężnej do wysokości 1 000 000 złotych']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [4]), test_dataset[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295247cee6f7f05",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ponownie krótko i konkretnie, bardzo dobrze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e28a42892e2b966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T14:59:38.798719Z",
     "start_time": "2025-01-17T14:59:38.387597Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 29. 1. Funkcjonariusz podlega corocznemu opiniowaniu służbowemu 2. Przełożony funkcjonariusza może wydać opinię służbową o funkcjonariuszu także w innym terminie niż określony w ust. 1, jednakże nie wcześniej niż po upływie 6 miesięcy od wydania poprzedniej opinii. 3. W wydanej opinii służbowej przełożony zamieszcza ogólną ocenę o opiniowanym funkcjonariuszu wyrażoną w skali od 1 do 6 (niedostateczna, mierna, dostateczna, dobra, bardzo dobra, wzorowa). 4. Przełożony jest obowiązany zapoznać funkcjonariusza z wydaną o nim opinią służbową w ciągu 30 dni od dnia jej sporządzenia. 5. W przypadku, jeżeli niemożliwe jest zapoznanie funkcjonariusza z opinią służbową w terminie, o którym mowa w ust. 4, termin ten biegnie od dnia ustania przeszkody. 6. Funkcjonariuszowi przysługuje prawo wniesienia odwołania od wydanej o nim opinii służbowej do wyższego przełożonego w terminie 14 dni od dnia zapoznania się z opinią. 7. Od opinii wydanej przez Szefa BOR przysługuje funkcjonariuszowi odwołanie do ministra właściwego do spraw wewnętrznych. 8. Opinia służbowa wydana wskutek odwołania, w trybie określonym w ust. 6 i 7, jest ostateczna. 9. Minister właściwy do spraw wewnętrznych określi, w drodze rozporządzenia, szczegółowe warunki i tryb opiniowania służbowego funkcjonariuszy, zapoznania się ich z opinią służbową oraz przypadki, w których zapoznanie się nie jest możliwe w terminie, o którym mowa w ust. 4, a także tryb wnoszenia i rozpatrywania odwołań od opinii służbowych.\n",
      "Question:\n",
      "Co jaki okres funkcjonariusze podlegają opiniowaniu służbowemu?\n",
      "True answer:\n",
      "['Funkcjonariusz podlega corocznemu opiniowaniu służbowemu.']\n",
      "predicted answer:\n",
      "['coroczny']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [14]), test_dataset[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd466518778531",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Wiadomo o co chodzi, jednak odmiana słowa zła. Można ją zrozumieć jednak nie jest w odpowiedinej formie. Znowu dość krótko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e97824ecee0b9a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:00:19.930400Z",
     "start_time": "2025-01-17T15:00:18.908763Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 223. 1. Opłaty jednorazowe za zgłoszenia, wnioski, oświadczenia i inne czynności przewidziane w ustawie powinny być uiszczane z góry, o ile ustawa lub rozporządzenie, o którym mowa w art. 222 ust. 3, nie przewiduje uiszczenia opłaty na wezwanie Urzędu Patentowego w określonym terminie. 2. Opłata jednorazowa za zgłoszenie może być również uiszczona w ciągu jednego miesiąca od daty doręczenia wezwania Urzędu Patentowego. 3. Jeżeli w wyniku złożonego wniosku o ponowne rozpatrzenie sprawy decyzja lub postanowienie Urzędu Patentowego zostało uchylone, opłata uiszczona od tego wniosku podlega zwrotowi. 4. W razie nieuiszczenia w terminie opłaty, o której mowa w ust. 1, postępowanie wszczęte w wyniku dokonania zgłoszenia lub złożenia wniosku podlega umorzeniu, bądź czynność uzależniona od opłaty zostaje zaniechana.\n",
      "Question:\n",
      "Co się stanie jeżeli nie zostanie uiszczona opłata dla wniosku patentowego?\n",
      "True answer:\n",
      "['postępowanie wszczęte w wyniku dokonania zgłoszenia lub złożenia wniosku podlega umorzeniu, bądź czynność uzależniona od opłaty zostaje zaniechana.']\n",
      "predicted answer:\n",
      "['postępowanie wszczęte w wyniku dokonania zgłoszenia lub złożenia wniosku podlega umorzeniu, bądź czynność uzależniona od opłaty zostaje zaniechana']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [21]), test_dataset[21])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3efe116567c471",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Bardzo dobrze, wręcz exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee34adc930a269b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:00:46.100911Z",
     "start_time": "2025-01-17T15:00:45.284936Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 7. 1. W każdym tygodniu kierowca wykorzystuje odpoczynek w wymiarze co najmniej 45 kolejnych godzin. Odpoczynek może być skrócony nie więcej niż do 36 kolejnych godzin, jeżeli zostanie udzielony w miejscowości gdzie znajduje się siedziba pracodawcy lub w miejscu zamieszkania kierowcy i nie więcej niż do 24 kolejnych godzin, jeżeli zostanie udzielony w innym miejscu. Tygodniowy nieprzerwany odpoczynek obejmuje dobowy odpoczynek przypadający w dniu, w którym kierowca rozpoczął odpoczynek tygodniowy. 2. Okres odpoczynku niewykorzystany wskutek skrócenia, o którym mowa w ust. 1, kierowca powinien wykorzystać nie później niż przed upływem trzeciego tygodnia następującego po tygodniu, w którym odpoczynek został skrócony. 3. Tygodniowy odpoczynek kierowca powinien wykorzystać nie później niż po sześciu dobowych okresach prowadzenia pojazdu. 4. Przełożenie tygodniowego odpoczynku do końca szóstego dobowego okresu prowadzenia jest dopuszczalne w przypadku, gdy całkowity czas prowadzenia pojazdu nie przekracza maksymalnej normy, odpowiadającej sześciu dobowym okresom prowadzenia.\n",
      "Question:\n",
      "Jaki jest tygodniowy odpoczynek kierowcy?\n",
      "True answer:\n",
      "['tygodniowy odpoczynek w wymiarze co najmniej 45 kolejnych godzin kierowca wykorzystuje nie później niż po sześciu dobowych okresach prowadzenia pojazdu']\n",
      "predicted answer:\n",
      "['dobowy odpoczynek przypadający w dniu, w którym kierowca rozpoczął odpoczynek tygodniowy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [23]), test_dataset[23])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8d380e9a76355",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Tutaj gorzej, o temacie ale bez konkretów nic nie wynika z odpowiedzi niestety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1fbb2f963f13dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:01:24.002412Z",
     "start_time": "2025-01-17T15:01:23.203800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 41. 1. Kontroler jest obowiązany zachować w tajemnicy informacje, które uzyskał w związku z wykonywaniem czynności służbowych. 2. Obowiązek zachowania tajemnicy trwa również po ustaniu zatrudnienia.\n",
      "Question:\n",
      "Jakie obowiązki ma pracownik nadzorujący czynności kontrolne?\n",
      "True answer:\n",
      "['jest obowiązany zachować w tajemnicy informacje, które uzyskał w związku z wykonywaniem czynności służbowych']\n",
      "predicted answer:\n",
      "['zachowanie w tajemnicy informacji, które uzyskał w związku z wykonywaniem czynności służbowych']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [33]), test_dataset[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56563f5ff89fe8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Bardzo dobrze, popranie krótko i zwięźle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f35df8802f129d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:01:54.186592Z",
     "start_time": "2025-01-17T15:01:53.665343Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 107. 1. Krajowy Związek Kas zrzesza regionalne i branżowe kasy. 2. Siedzibą Krajowego Związku Kas jest Warszawa. 3. Krajowy Związek Kas prowadzi działalność na podstawie ustawy i statutu Krajowego Związku Kas.\n",
      "Question:\n",
      "Które miasto jest siedzibą Krajowego Związku Kas?\n",
      "True answer:\n",
      "['Warszawa']\n",
      "predicted answer:\n",
      "['Warszawa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [57]), test_dataset[57])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43f1af80212ddd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Dobrze, exact match, łatwy przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a32951dd5bc89c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:02:11.649517Z",
     "start_time": "2025-01-17T15:02:11.106765Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 208. Oględzin lub badań ciała, które mogą wywołać uczucie wstydu, powinna dokonać osoba tej samej płci, chyba że łączą się z tym szczególne trudności; inne osoby odmiennej płci mogą być obecne tylko w razie konieczności.\n",
      "Question:\n",
      "Kto powinien dokonywać badań ciała, jeżeli może ono wywoływać uczucie wstydu?\n",
      "True answer:\n",
      "['Badań ciała, które mogą wywołać uczucie wstydu, powinna dokonać osoba tej samej płci, chyba że łączą się z tym szczególne trudności; inne osoby odmiennej płci mogą być obecne tylko w razie konieczności']\n",
      "predicted answer:\n",
      "['osoba tej samej płci']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [77]), test_dataset[77])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0f3f9f4688621",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Dużo krótsza, jednak konkretna i poprawna odpowiedz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf181b9a71e21dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:02:39.776422Z",
     "start_time": "2025-01-17T15:02:39.426577Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 8. § 1. W postępowaniu wykonawczym skazany może korzystać z pomocy obrońcy ustanowionego w tym postępowaniu lub pełnomocnika. § 2. W postępowaniu przed sądem skazany musi mieć obrońcę, jeżeli: 1) jest głuchy, niemy lub niewidomy, 2) zachodzi uzasadniona wątpliwość co do jego poczytalności, 3) nie ukończył 18 lat, 4) nie włada językiem polskim. § 3. Skazany pozbawiony wolności może porozumiewać się ze swoim obrońcą lub pełnomocnikiem będącym adwokatem podczas nieobecności innych osób oraz korespondencyjnie lub telefonicznie. Rozdział IV Postępowanie wykonawcze Oddział 1 Wykonywanie orzeczeń\n",
      "Question:\n",
      "Czy skazany który nie ukończył 18 lat musi mieć obrońcę?\n",
      "True answer:\n",
      "['tak']\n",
      "predicted answer:\n",
      "['nie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [113]), test_dataset[113])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d8b6d7bc4a137",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Krótkoi konkretnie, porpawnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8884cd47b8856f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:03:11.937956Z",
     "start_time": "2025-01-17T15:03:11.005799Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Art. 3. Celem łowiectwa jest: 1) ochrona, zachowanie różnorodności i gospodarowanie populacjami zwierząt łownych, 2) ochrona i kształtowanie środowiska przyrodniczego na rzecz poprawy warunków bytowania zwierzyny, 3) uzyskiwanie możliwie wysokiej kondycji osobniczej i jakości trofeów oraz właściwej liczebności populacji poszczególnych gatunków zwierzyny przy zachowaniu równowagi środowiska przyrodniczego, 4) spełnianie potrzeb społecznych w zakresie uprawiania myślistwa, kultywowania tradycji oraz krzewienia etyki i kultury łowieckiej.\n",
      "Question:\n",
      "Co jest celem łowiectwa?\n",
      "True answer:\n",
      "['ochrona, zachowanie różnorodności i gospodarowanie populacjami zwierząt łownych']\n",
      "predicted answer:\n",
      "['ochrona, zachowanie różnorodności i gospodarowanie populacjami zwierząt łownych']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_answer(model, torch.utils.data.Subset(test_dataset, [257]), test_dataset[257])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd453184b61bc95f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "bardzo dobra odpowiedz, wręcz exact match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21e43b5a478d1a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Wnioski\n",
    "Bardzo ciekawe i ponownie, wartościowe ćwiczenie. Szkoda niestety, że nie udało mi się mimo szczerych chęci dotrenować własnego modelu T5.\n",
    "Próba była na macbooku M3 pro - estyomwany czas to było 700h - odpuściłem\n",
    "Próba na Collabie - 10h - rozsądnie, jednak dwie próby collab zakończył, był to darmowy zasób ktory po prostu ktoś wywłaszczył. 3 próby już nie podjemowałem.\n",
    "\n",
    "\n",
    "Wyniki bardzo ciekawe, tutaj warto zauważyć, że pomimo stosunkowo niskich metrych EM i F1, wyniki są dość dobre. Warto o tym pamiętać w Data Science, że metryki to jedno, jednak warto zawsze je przejrzeć własnoręcnzie i zinterprtować, podobna sytuacja ma miejsce w segmentacji obiektów, tam metryki też są zazwyczaj niskie, (mean-acc na poziomie 40%) jednak w prkatyce może to oznaczać bardzo dobre modele.\n",
    "Praktycznie na 10 przetestowanych pytań model na 9 odpowiedział bardzo dobrze.\n",
    "Jedno pomylił. Ma tendencje do udzielania krótszych odpowiedzi, co moim zdaniem na plus, ale zależy od problemu.\n",
    "\n",
    "Zadanie pzowoliło znowu dotknąć praktycznego problemu, dotrenować na dużym popularnym zbiorze, i testować na 'prywatnym' datasecie. Pozwoliło mi to zrozumieć jak mogą działać, może nie najwieksze LLM jak Gpt-4 ale jakieś mniejsze które cieszą sie tez duża popularnościa. Ponadto zapoznanie się z bibliotekami datasets i transformers, na plus, ciężkie złożone biblioteki ale z ogromnymi możliowściami.\n",
    "Bardzo ciekawe ćwiczenie. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3298667a0aa81",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Questions\n",
    "- Does the performance on the validation dataset reflects the performance on your test set?\n",
    "    Nie, do przewidzenia było że na zbiorze validacyjnym na kótrym był dotrenowany T5, wynik dużo lepszy, jednak mimo słabych metryk na Test secie, odpowiedzi modelu sensowe.\n",
    "- What are the outcomes of the model on your test questions? Are they satisfying? If not, what might be the reason for that?\n",
    "    Odpowiedzi są krótsze niż ground truem jednak moim zdaniem są ok, satysfakcjonujące.\n",
    "- Why extractive question answering is not well suited for inflectional languages?\n",
    "    Bo praktycznie zawsze odpowiedz wyekstraktowana będzie w złej formie, przez co wygląda to i brzmi nienaturalnie. W języku takim jak polski, dużo lepiej pasuje AQA niż EQA, które umożliwa zmianę te formy i odpowiedz bardziej w 'ludzkim' stylu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4e3ac66895d17",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
