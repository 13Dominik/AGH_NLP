{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:00.205388Z",
     "start_time": "2024-11-28T19:46:59.388761Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53f103557579f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b635d7a63ae5f550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:02.961775Z",
     "start_time": "2024-11-28T19:47:00.206210Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   3        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1  31        Tak więc nic nie zapobiega fałszywym ocenom po..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "df_texts = texts['corpus']\n",
    "df_texts = pd.DataFrame.from_dict(df_texts)\n",
    "df_texts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101da90083bd663e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:09.230348Z",
     "start_time": "2024-11-28T19:47:02.962383Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>566392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>65404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         8     566392      1\n",
       "1         8      65404      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds_qa = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "data_qa = ds_qa['test']\n",
    "df_qa = pd.DataFrame(data_qa)\n",
    "df_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ada56e7d01c8561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:58:31.566256Z",
     "start_time": "2024-11-28T20:58:30.503339Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Rozpoczęcie nowego biznesu online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>„Dzień roboczy” i „termin płatności” rachunków</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Nowy właściciel firmy – Jak działają podatki d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>Hobby kontra biznes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>Czeki osobiste zamiast firmowych</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>Czy amerykański kodeks podatkowy wymaga, aby w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>Jak mogę zarejestrować firmę w Wielkiej Brytan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>Czym są „podstawy biznesowe”?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   0        Co jest uważane za wydatek służbowy w podróży ...\n",
       "1   4        Wydatki służbowe - ubezpieczenie samochodu pod...\n",
       "2   5                        Rozpoczęcie nowego biznesu online\n",
       "3   6           „Dzień roboczy” i „termin płatności” rachunków\n",
       "4   7        Nowy właściciel firmy – Jak działają podatki d...\n",
       "5   9                                      Hobby kontra biznes\n",
       "6  11                         Czeki osobiste zamiast firmowych\n",
       "7  12        Czy amerykański kodeks podatkowy wymaga, aby w...\n",
       "8  13        Jak mogę zarejestrować firmę w Wielkiej Brytan...\n",
       "9  14                            Czym są „podstawy biznesowe”?"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Questions dataset \n",
    "data_queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "df_q = pd.DataFrame(data_queries['queries'])\n",
    "df_q.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4a07290483f3ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:10.722886Z",
     "start_time": "2024-11-28T19:47:10.717110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_qa['corpus-id'] = df_qa['corpus-id'].astype(int)\n",
    "df_texts['_id'] = df_texts['_id'].astype(int)\n",
    "df_q['_id'] = df_q['_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31d1805784fd186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:10.739413Z",
     "start_time": "2024-11-28T19:47:10.723434Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1706 entries, 0 to 1705\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   answear   1706 non-null   object\n",
      " 1   question  1706 non-null   object\n",
      " 2   class     1706 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 40.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Positive class creation\n",
    "df = df_qa.merge(df_texts[['_id', 'text']], left_on='corpus-id', right_on='_id', how='left')\n",
    "df = df.rename(columns={'text': 'answear'})\n",
    "df = df.drop(columns=['_id', 'score'])\n",
    "df = df.merge(df_q[['_id', 'text']], left_on='query-id', right_on='_id', how='left')\n",
    "df['class'] = 1\n",
    "df = df.drop(columns=['query-id', 'corpus-id', '_id'])\n",
    "df = df.rename(columns={'text': 'question'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24c6283f6c7075a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.276639Z",
     "start_time": "2024-11-28T19:47:10.740392Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4265 entries, 0 to 4264\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   answear   4265 non-null   object\n",
      " 1   question  4265 non-null   object\n",
      " 2   class     4265 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 100.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Negative class creation\n",
    "questions = df['question']\n",
    "answears = df['answear']\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for question in questions:\n",
    "    used_answers = set(df[df['question'] == question]['answear'])\n",
    "    available_answers = list(set(answears) - used_answers)\n",
    "    if available_answers:\n",
    "        new_answer = random.choice(available_answers)\n",
    "        new_rows.append({'question': question, 'answear': new_answer, 'class': 0})\n",
    "        \n",
    "for question in questions[:int(len(questions) / 2)]:\n",
    "    used_answers = set(df[df['question'] == question]['answear'])\n",
    "    available_answers = list(set(answears) - used_answers)\n",
    "    if available_answers:\n",
    "        new_answer = random.choice(available_answers)\n",
    "        new_rows.append({'question': question, 'answear': new_answer, 'class': 0})\n",
    "        \n",
    "new_df = pd.DataFrame(new_rows)\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8533d32204746c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.284492Z",
     "start_time": "2024-11-28T19:47:11.278366Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jak zdeponować czek wystawiony na współpracownika w mojej firmie na moje konto firmowe?</s>Poproś o ponowne wystawienie czeku właściwemu odbiorcy.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_row'] = df['question'] + \"</s>\" + df['answear']\n",
    "df.iloc[0]['data_row']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2896d8e809a7b27b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.292639Z",
     "start_time": "2024-11-28T19:47:11.285097Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4260 entries, 0 to 4264\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   class     4260 non-null   int64 \n",
      " 1   data_row  4260 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 99.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(['data_row'], inplace=True)\n",
    "df.drop(['question', 'answear'], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4d9138707a7876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.296577Z",
     "start_time": "2024-11-28T19:47:11.293139Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_row\n",
       "class          \n",
       "0          2554\n",
       "1          1706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "272379667a648eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.299719Z",
     "start_time": "2024-11-28T19:47:11.297120Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>data_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jak zdeponować czek wystawiony na współpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jak zdeponować czek wystawiony na współpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Czy mogę wysłać przekaz pieniężny z USPS jako ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                           data_row\n",
       "0      1  Jak zdeponować czek wystawiony na współpracown...\n",
       "1      1  Jak zdeponować czek wystawiony na współpracown...\n",
       "2      1  Czy mogę wysłać przekaz pieniężny z USPS jako ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47456c5f2cf17e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:11.301672Z",
     "start_time": "2024-11-28T19:47:11.300112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'data_row' : 'text', 'class' : 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29417e60a7803102",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Ważne! \n",
    "Z całą pewnościa wiele zalezy od utworzenia datasetu. W moim przypadku ze zbioru q-a wziąłem wszystkie pary (q sie powtarzają ale z innymi a). I tak powstało 1706 rekordów klasy '1' pozytywnej. Klase negatywną utworzyłem biorąc 1.5x wszystkie q i losując do nich a które nie było przy zadnym wystapieniu tego konkretnego 'q'. Tak tworze zlą odpowiedz na pytanie, z pewnosci ma to ogrmony wplyw na dalsze wyniki. Mozna by pokusić sie o inne stworzenie datsetu i wyniki beda mocno sie roznic, jednak poki co zostaje przy takim rozwiazaniu.\n",
    "\n",
    "1.5x bo klasa negatywna zgodnie z poleceniam ma byc wieksza niz klasa pozytywna. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be95051ff221c23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f3360987984215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:12.226463Z",
     "start_time": "2024-11-28T19:47:11.302144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cf722be8634e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:13.763464Z",
     "start_time": "2024-11-28T19:47:12.228316Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer.sep_token = \"</s>\" # unecessary but to make it clear!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'allegro/herbert-base-cased',\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86e58cf0c56d2157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:13.774911Z",
     "start_time": "2024-11-28T19:47:13.765095Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Jak zdeponować czek wystawiony na współpracownika w mojej firmie na moje konto firmowe? </s>Po prostu poproś współpracownika o podpisanie odwrotu, a następnie zdeponowanie go. Nazywa się to czekiem strony trzeciej i jest całkowicie legalne. Nie zdziwiłbym się, gdyby czek był dłuższy i, jak zawsze, nie dostaniesz pieniędzy, jeśli czek nie zostanie zrealizowany. Teraz możesz mieć problemy, jeśli jest to duża kwota lub nie jesteś zbyt dobrze znany w banku. W takim przypadku możesz poprosić współpracownika o udanie się do banku i zatwierdzenie go przed kasjerem za pomocą dowodu tożsamości. Technicznie nawet nie musisz tam być. Każdy może wpłacić pieniądze na Twoje konto, jeśli ma numer konta. Mógł też po prostu wpłacić go na swoje konto i wypisać czek na firmę. </s>\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(df['text'].iloc[1],  return_tensors=\"pt\")\n",
    "decoded = tokenizer.decode(encoded[\"input_ids\"][0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be0b8ed9571be87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:13.779590Z",
     "start_time": "2024-11-28T19:47:13.775969Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 2912, 5019, 3400, 2284, 3825, 43923, 1998, 3008, 10986, 1019, 6892, 9425, 1998, 6403, 10747, 2771, 8090, 1550, 2, 2620, 4388, 9037, 1062, 3008, 10986, 1007, 26991, 11708, 2213, 1947, 1011, 5822, 5019, 3400, 2429, 2010, 1899, 29130, 2106, 2022, 2063, 2052, 2369, 3441, 9102, 1009, 2092, 7576, 41915, 1899, 2351, 19806, 13405, 2022, 1947, 4839, 3825, 2430, 16206, 1009, 1947, 2217, 3589, 1947, 1997, 5132, 17773, 3929, 1947, 3346, 3825, 1997, 3392, 32439, 1899, 4004, 11814, 3889, 5865, 1947, 3346, 2092, 2063, 9269, 10523, 2491, 1997, 10724, 4489, 3394, 6847, 1019, 8324, 1899, 1049, 4975, 3714, 11814, 28961, 3008, 10986, 1007, 39455, 2022, 2041, 8324, 1009, 11713, 3021, 2010, 2534, 42611, 2695, 2163, 6555, 23661, 16282, 1899, 8550, 12004, 2697, 1997, 20054, 2731, 2458, 1899, 6179, 2402, 37988, 3638, 1998, 20819, 10747, 1947, 3346, 2185, 7440, 13870, 1899, 40372, 2375, 2184, 4388, 37988, 2010, 1998, 3413, 10747, 1009, 2017, 5774, 3825, 1998, 9569, 1899, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = tokenizer(df['text'].iloc[1],  truncation=True, padding=\"max_length\")\n",
    "print(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ae5b0bb8a8a0380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:14.188726Z",
     "start_time": "2024-11-28T19:47:13.780596Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 3408\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 426\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 426\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "dataset['train'] = dataset['train'].remove_columns(['__index_level_0__'])\n",
    "dataset['test'] = dataset['test'].remove_columns(['__index_level_0__'])\n",
    "dataset['val'] = dataset['val'].remove_columns(['__index_level_0__'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e83866c3661e6390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:47:15.005295Z",
     "start_time": "2024-11-28T19:47:14.189319Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38193f1289d145a3a9cbd5706ea5231f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5d46e9de9b408a85734e510fa222dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90357707ef85434b9f448b5581e1ba97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3408\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a164e2007081d190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:52:28.407089Z",
     "start_time": "2024-11-28T19:52:28.398641Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir= \"./output/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=400,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    learning_rate=2e-05,\n",
    "    num_train_epochs=1,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=300,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50\n",
    "    #use_mps_device=True,\n",
    "    #fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d0d8ccec042d297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:52:29.553242Z",
     "start_time": "2024-11-28T19:52:28.709824Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60caa19e50acf49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:52:29.928660Z",
     "start_time": "2024-11-28T19:52:29.910411Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=2137),\n",
    "    eval_dataset=tokenized_datasets[\"val\"].shuffle(seed=2137),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfd1c506d27cd299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T19:53:41.871521Z",
     "start_time": "2024-11-28T19:53:40.842263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if model is not trained : \n",
    "#trainer.train() \n",
    "\n",
    "#if model trained\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./output/checkpoint-3408/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f876211c1adc02d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:39:26.905520Z",
     "start_time": "2024-11-28T20:38:13.499909Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inferencja modelu:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "test_dataset = tokenized_datasets['test']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for example in test_dataset:\n",
    "        input_ids = torch.tensor(example['input_ids']).unsqueeze(0)  # Dodaj batch dimension\n",
    "        attention_mask = torch.tensor(example['attention_mask']).unsqueeze(0)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        predictions.append(predicted_class)\n",
    "        labels.append(example['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91bc86705514902e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:39:26.910543Z",
     "start_time": "2024-11-28T20:39:26.907683Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae0d4feeabfba514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:39:26.913923Z",
     "start_time": "2024-11-28T20:39:26.911209Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = tokenized_datasets['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13d5ca5c7b5e9905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:39:35.851773Z",
     "start_time": "2024-11-28T20:39:35.845817Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność modelu: 0.8896713615023474\n",
      "F1 modelu: 0.8772845953002611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  accuracy_score, f1_score\n",
    "print(\"Dokładność modelu:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1 modelu:\", f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32862962ecf96611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:26:29.567509Z",
     "start_time": "2024-11-28T20:26:29.562346Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_pred(model, data_row):\n",
    "    input_ids = torch.tensor(data_row['input_ids']).unsqueeze(0)  # Dodaj batch dimension\n",
    "    attention_mask = torch.tensor(data_row['attention_mask']).unsqueeze(0)\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    label = data_row['label']\n",
    "    return label, predicted_class\n",
    "\n",
    "def visualize_pred(model, data_row):\n",
    "    print(\"tekst:\")\n",
    "    print(data_row['text'])\n",
    "    print(\"Prawda\" if data_row['label'] == 1 else \"Fałsz\")\n",
    "    print(\"Predykcja modelu:\")\n",
    "    label, pred = get_pred(model, data_row)\n",
    "    print(\"Prawda\" if label == 1 else \"Fałsz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bad01af18a0b0e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:26:43.574020Z",
     "start_time": "2024-11-28T20:26:43.372469Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tekst:\n",
      "Jaką wewnętrzną, niepieniężną wartość ma złoto jako towar?</s>Musisz uruchomić skanowanie antywirusowe na swoich komputerach, aby upewnić się, że nie masz uruchomionego programu keyloggera. Pomyślałbym również o wyznaczeniu jednego starego komputera, aby miał dostęp tylko do twoich kont bankowych i nie robił nic poza tym. Jeśli Twój komputer jest zainfekowany, za każdym razem, gdy się logujesz, Twoje karty kredytowe mogą być zagrożone.\n",
      "Fałsz\n",
      "Predykcja modelu:\n",
      "tensor([[0.9986, 0.0014]], grad_fn=<SoftmaxBackward0>)\n",
      "Fałsz\n"
     ]
    }
   ],
   "source": [
    "visualize_pred(model, test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31db42fd46126d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:08:41.339496Z",
     "start_time": "2024-11-28T20:08:41.142284Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tekst:\n",
      "Czy zawsze powinieneś maksymalizować składki na swoje 401k?</s>Dopóki znajdujesz się w niższym przedziale podatkowym – prawdopodobnie lepiej byłoby teraz zapłacić podatki i zainwestować w Roth IRA/401K. Jednak powinieneś inwestować na swoją emeryturę teraz, a nie później, ze względu na efekt łączenia, a także zyskasz dopasowanie pracodawcy (jeśli jest dostępne).\n",
      "Prawda\n",
      "Predykcja modelu:\n",
      "Prawda\n"
     ]
    }
   ],
   "source": [
    "visualize_pred(model, test_dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b920b58a12a5d9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:09:23.052051Z",
     "start_time": "2024-11-28T20:09:22.862150Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tekst:\n",
      "Czy istnieje bardziej elastyczna usługa wykresów giełdowych, np. pozwalając na wybór kolorów przy porównywaniu wielu zapasów?</s>Nie sądzę, aby istniały jakiekolwiek narzędzia internetowe, które pozwoliłyby ci to zrobić. Wysiłek wymagany do zbudowania w porównaniu z postrzeganymi korzyściami dla użytkowników jest mniejszy. Wszyscy dostawcy sieci chcą, aby wyświetlanie danych było jak najprostsze; udostępnianie większej liczby funkcji czasami dezorientuje przeciętnego użytkownika.\n",
      "Prawda\n",
      "Predykcja modelu:\n",
      "Prawda\n"
     ]
    }
   ],
   "source": [
    "visualize_pred(model, test_dataset[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f22d9b6647621f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wnioski (część 1)\n",
    "Bardzo dobre wyniki, nie spodziewałem się aż tak dobrych, gdy zauważyłem acc na poziomie 0.88 myślałem, że to błąd i będzie trzeba poprawiać jednak pow eryfikacji wielu przykładów wynik zdaje się być poprawny. Oczywiście przykłady to odpowiedzi na pytania, więc część pozostaje do interpretacji własnej jednak moim zdaniem działa to bardzo dobrze. Wyniki z pewnością zawdzięczamy pre-trenowanemu modelowi który jest duży i bez tego prwnie dość dobrze by sobie poradził, jednak fine-tuning na pewno pomógł. Bardzo ciekawe ćwiczenia póki co, praktycznie dostrajanie LLM, to zdaje się czymś bardzo praktycznym co można w zasadzie w ten sam sposób zaimplementować do dużego komercyjnego pomysłu. Pierwsze doświadczenie z biblioteką hugging face i treningiem w niej, dość intuicyjna, powiedziałbym, że pomiędzy kerasem a pytorchem. Pozytywnie. Bardzo ciekawy proces, obróbka datasetu, finetuning gotowego LLM polskiego po czym test na naszych danych. Początkowo dataset wydawał mi się zbyt mały i te 5k przykładów niewystarczające, jednak do finetuningu wystarczyło jak widać."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f74467536a4bdc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Re ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3cfdb365fa953a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T20:48:45.999162Z",
     "start_time": "2024-11-28T20:48:45.778411Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'node-1', 'cluster_name': 'my-application-cluster', 'cluster_uuid': 'gBI4PdSoQuCa8sMPxLY-yQ', 'version': {'number': '8.15.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '98adf7bf6bb69b66ab95b761c9e5aadb0bb059a3', 'build_date': '2024-09-19T10:06:03.564235954Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "es = Elasticsearch([\"http://elastics:password@localhost:9200\"], verify_certs=False)\n",
    "try:\n",
    "    resp = es.info()\n",
    "    print(resp)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ff40016376103c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T21:00:42.833333Z",
     "start_time": "2024-11-28T21:00:42.824795Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_dcg(scores):\n",
    "    return sum(score / np.log(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "\n",
    "def compute_ndcg(relevant_scores, retrieved_scores, k=5):\n",
    "    dcg = compute_dcg(retrieved_scores[:k])  # to sa te ktore zwrocil nasz 'model'\n",
    "    ideal_dcg = compute_dcg(\n",
    "        sorted(relevant_scores, reverse=True)[:k])  # relevant uzywamy do idealnego dcg (idealne ulozenie odpowiedzi)\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "\n",
    "NDCG_SIZE = 10\n",
    "\n",
    "\n",
    "def search_and_compute_ndcg(index_name, analyzator_content, test_data, ndcg_size, query_column_name):\n",
    "    ndcg_scores = []\n",
    "\n",
    "    # obliczamy dla kazdej query dostepnej w testowym zbiorze danych\n",
    "    for index, row in test_data.iterrows():\n",
    "        # query id\n",
    "        query_id = row[\"query-id\"]\n",
    "        # query text\n",
    "        query = df_q[df_q['_id'] == str(query_id)][query_column_name].values[0]\n",
    "        # Wykonanie zapytania do Elasticsearch\n",
    "        search_query = {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        analyzator_content: query,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        # bierzemy 5 pierwszych dopasowań od Elastic search (dostał query) zwraca nam 5 dokumentów\n",
    "        response = es.search(index=index_name, body=search_query, size=ndcg_size)\n",
    "        retrieved_docs = [hit[\"_id\"] for hit in response[\"hits\"][\"hits\"]]  # id 5 dokumentow zwrocone przez ES\n",
    "        # Wszysktie A które pasuja do Q (z labelowanego dataset)\n",
    "        good_answers = df_qa[df_qa['query-id'] == int(query_id)]\n",
    "        # sortuje je po ich 'score', one i tak mają 1 ale na przyszlosc z lepszym datasetem zeby gralo bo tak sie realizuje IDCG\n",
    "        good_answers = good_answers.sort_values(by='score', ascending=False)\n",
    "        # Biore posortowane kolejne elementy z dobrymyim odpowiedziami, jesli nie ma ich (5) to uzupelniam 0 ami aby było zawsze 5 elementów - prawidlowe ndcg tak działa\n",
    "        relenvant_answears = list(good_answers['score'][:ndcg_size]) + [0] * (\n",
    "                    ndcg_size - len(good_answers))  # idealne odpowiedzi\n",
    "        # print(relenvant_answears) -> cos w stylu [1,1,0,0,0]\n",
    "\n",
    "        retrived_answears = [0 for _ in range(ndcg_size)]  #otrzymane odpowiedzi\n",
    "        for idx, doc_found in enumerate(retrieved_docs):\n",
    "            if int(doc_found) in good_answers['corpus-id'].values:\n",
    "                retrived_answears[idx] = good_answers[good_answers['corpus-id'] == int(doc_found)]['score'].iloc[0]\n",
    "\n",
    "        #print(retrived_answears) # -> cos w stylu [0,1,0,0,0]\n",
    "        ndcg = compute_ndcg(relenvant_answears, retrived_answears, k=5)\n",
    "        ndcg_scores.append(ndcg)  # ndcg dla kazdego query sumujemy\n",
    "\n",
    "    # Zwracamy średnie NDCG dla wszystkich zapytań\n",
    "    return np.mean(ndcg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ce4fb1fb3fd7b644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T22:40:22.836095Z",
     "start_time": "2024-11-28T22:40:22.829832Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa_no_duplicates = df_qa.drop_duplicates(subset='query-id')\n",
    "index_name = \"fiqa_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "81714f2549f0f2ab",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T23:12:57.373128Z",
     "start_time": "2024-11-28T23:12:57.366726Z"
    }
   },
   "outputs": [],
   "source": [
    "def re_rank_answears(model, tokenizer, retrieved_docs_text, query, retrived_answears):\n",
    "    \"\"\"\n",
    "    przyklad:\n",
    "    retrived_answears -> [0,0,1,0,1]\n",
    "    re_ranked ---------> [1,0,0,1,0] \n",
    "    \"\"\"\n",
    "    #data w takim formacie jak model byl trenowany: question<sep>answear\n",
    "    data = [query + \"</s>\" + text[:512] for text in retrieved_docs_text]\n",
    "    # tokenizujemy zeby zrobic inferencje, tokenizer oczywiscie ten sam\n",
    "    tokenized_data = [tokenizer(docs, padding=\"max_length\", truncation=True) for docs in data]\n",
    "    probs = []\n",
    "    for text in tokenized_data:\n",
    "        input_ids = torch.tensor(text['input_ids']).unsqueeze(0)  # Dodaj batch dimension\n",
    "        attention_mask = torch.tensor(text['attention_mask']).unsqueeze(0)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        # patrzymy na prawdopodobienstwo tylko klasy '1' co oznacza ze zdanie jest prawdzie, czyli Q-A dobrze dopasowane -> to chcemy ustawiac wyzej w rankingu\n",
    "        probs.append(float(probabilities[0][1]))\n",
    "    # probs i odpowiedzi (odpowiedzi jako wartosci punktowe, jak dobra to odpowiedz)\n",
    "    probs_and_retrived_answears = [(prob, ans) for prob, ans in zip(probs, retrived_answears)]\n",
    "    # sortujemy je po wyzej wyliczonych probs\n",
    "    probs_and_retrived_answears_sorted = sorted(probs_and_retrived_answears, key=lambda x: x[0], reverse=True)\n",
    "    # i bierzemy tylko odpowiedzi cos w stylu: [1, 0,0,1,0]\n",
    "    re_rankeswear = [ans[1] for ans in probs_and_retrived_answears_sorted]\n",
    "    return re_rankeswear\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cdcfd444952c8fc2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T23:12:57.818088Z",
     "start_time": "2024-11-28T23:12:57.814441Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_and_compute_ndcg_reranked(index_name, analyzator_content, test_data, ndcg_size, query_column_name, tokenizer, model):\n",
    "    ndcg_scores = []\n",
    "\n",
    "    # obliczamy dla kazdej query dostepnej w testowym zbiorze danych\n",
    "    for index, row in test_data.iterrows():\n",
    "        # query id\n",
    "        query_id = row[\"query-id\"]\n",
    "        # query text\n",
    "        query = df_q[df_q['_id'] == str(query_id)][query_column_name].values[0]\n",
    "        # Wykonanie zapytania do Elasticsearch\n",
    "        search_query = {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        analyzator_content: query,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        # bierzemy 5 pierwszych dopasowań od Elastic search (dostał query) zwraca nam 5 dokumentów\n",
    "        response = es.search(index=index_name, body=search_query, size=ndcg_size)\n",
    "        #print(response)\n",
    "        retrieved_docs = [hit[\"_id\"] for hit in response[\"hits\"][\"hits\"]]  # id 5 dokumentow zwrocone przez ES\n",
    "        retrieved_docs_text = df_texts[df_texts['_id'].isin([int(elem) for elem in retrieved_docs])]['text'].tolist()\n",
    "        # Wszysktie A które pasuja do Q (z labelowanego dataset)\n",
    "        good_answers = df_qa[df_qa['query-id'] == int(query_id)]\n",
    "        # sortuje je po ich 'score', one i tak mają 1 ale na przyszlosc z lepszym datasetem zeby gralo bo tak sie realizuje IDCG\n",
    "        good_answers = good_answers.sort_values(by='score', ascending=False)\n",
    "        # Biore posortowane kolejne elementy z dobrymyim odpowiedziami, jesli nie ma ich (5) to uzupelniam 0 ami aby było zawsze 5 elementów - prawidlowe ndcg tak działa\n",
    "        relenvant_answears = list(good_answers['score'][:ndcg_size]) + [0] * (\n",
    "                    ndcg_size - len(good_answers))  # idealne odpowiedzi\n",
    "        # print(relenvant_answears) -> cos w stylu [1,1,0,0,0]\n",
    "\n",
    "        retrived_answears = [0 for _ in range(ndcg_size)]  #otrzymane odpowiedzi\n",
    "        for idx, doc_found in enumerate(retrieved_docs):\n",
    "            if int(doc_found) in good_answers['corpus-id'].values:\n",
    "                retrived_answears[idx] = good_answers[good_answers['corpus-id'] == int(doc_found)]['score'].iloc[0]\n",
    "\n",
    "        #print(retrived_answears) # -> cos w stylu [0,1,0,0,0]\n",
    "        # rerankujemy odpowiedzi zgodnie z tym jakie proba przewidzi model:\n",
    "        reranked_answears = re_rank_answears(model, tokenizer, retrieved_docs_text, query, retrived_answears)\n",
    "        ndcg = compute_ndcg(relenvant_answears, reranked_answears, k=5)\n",
    "        ndcg_scores.append(ndcg)  # ndcg dla kazdego query sumujemy\n",
    "\n",
    "    # Zwracamy średnie NDCG dla wszystkich zapytań\n",
    "    return np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "164a81341ead494",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T23:14:54.983472Z",
     "start_time": "2024-11-28T23:14:54.980430Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_ndcg_query = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates[:100], NDCG_SIZE, query_column_name='text')\n",
    "mean_ndcg_query_re_ranked = search_and_compute_ndcg_reranked(index_name, 'content_synon', qa_no_duplicates[:100], NDCG_SIZE, query_column_name='text', tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b970dfe7d88a4651",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T23:14:28.844694Z",
     "start_time": "2024-11-28T23:14:28.842912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla FTS Elastic search: 0.14124358264284925\n",
      "Średnie NDCG dla FTS Elastic search (Reranked): 0.061823324533972775\n"
     ]
    }
   ],
   "source": [
    "print(\"Średnie NDCG dla FTS Elastic search:\",mean_ndcg_query)\n",
    "print(\"Średnie NDCG dla FTS Elastic search (Reranked):\",mean_ndcg_query_re_ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679038bd40b525",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wnioski (część 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669eabb4e391fc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wyniki po rearankigu (testowane na 100 przykładach żeby był to rozsądny czas) o dziwo spadły, może to wynikać wprost ze specyfiki modelu, datasetu, trzeba by również poeksperymentować z róźnymi wartościami top-n i parametrami ES, z pewnością można to podciągnąć. Outputy modelu są bardzo duże >0.99 lub bardzo małe <0.01 stąd sortujemy liczby po bardzo małych różnicach, praktycznie niezauważalnych różnicach, zatem nie przynosi to poprawy a wręcz psuje wynik. \n",
    "Idea rearankigu na pierwszy rzut oka nieintuicyjna, jednak po kolejnym przeczytaniu i zastanowieniu się logiczna. Ciekawe połączenie, czy praktyczne? Ciężko powiedzieć - nie wiem. Na pewno duuuużo wolniejsze rozwiązanie, wręcz bardzo wolne, stąd domyślam się, że nie robi się tak w praktyce. Ponownie pozwoliło popracować z modelami, z inferencją i trzbea pilnować wielu rzeczy, takich jak chociażby używanie tego samego tokenizera itd. Wyniki dla NDCG jak i klasyfikacji można z pewnościa poprawić i to dużo, dużo z pewnościa zależało od tego jak stowrzyłem dataset do treningu. Jednak wydaje mi się, że chodzi tutaj o zrozumienie i załapanie bibliotek i co jak działa niż maksowanie wyniku.Cwiczenie czasochłonne, jednak solida porcja wiedzy i praktyki. Zapoznałem się z API hugging face do NLP, finetuning, używanie gotowych dużych modeli, robienie datasetu, ocena modelu, próba zastosowania LLM do uspranwienia FTS. Bardzo ciekawe.\n",
    "\n",
    "Pytania:\n",
    "Do you think simpler methods, like Bayesian bag-of-words model, would work for sentence-pair classification? Justify your answer.\n",
    "Myśle, że nie. Są to zbyt złożone teksty, prostsze modele sprawdizły by się do zadania typu klasyfikacja spam/nie spam, gdzie tak jak bayesowski model może sie nauczyć po prostu, że są pewne słowa które mocno świadczą o spamie i tak podejmować decyzje. DO klasyfikacji par, trzeba mocno uwzględniać obie pary stąd proste modele wydają się być złym wyborem.\n",
    "What hyper-parameters you have selected for the training? What resources (papers, tutorial) you have consulted to select these hyper-parameters?\n",
    "Poradniki z hugging face\n",
    "Think about pros and cons of the neural-network models with respect to natural language processing. Provide at least 2 pros and 2 cons.\n",
    "+Większa pojemność modelu\n",
    "+Bardziej przypominają 'ludzkie' decyzje\n",
    "-Czas treningu/inferencji\n",
    "-implementacje, wersje bibliotek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "693e758b5b1756cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T22:38:52.224236Z",
     "start_time": "2024-11-28T22:38:52.223200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5ba2f71dbad97",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
