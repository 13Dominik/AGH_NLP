{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:38.833215Z",
     "start_time": "2024-11-17T16:03:32.566237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  _id title                                               text\n0   3        Nie mówię, że nie podoba mi się też pomysł szk...\n1  31        Tak więc nic nie zapobiega fałszywym ocenom po...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td></td>\n      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31</td>\n      <td></td>\n      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pl import Polish\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from Levenshtein import distance as lv_distance\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load text corpus\n",
    "texts = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "df_texts = texts['corpus']\n",
    "df_texts = pd.DataFrame.from_dict(df_texts)\n",
    "df_texts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df154f0446db7f27",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:41.320635Z",
     "start_time": "2024-11-17T16:03:38.835827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since clarin-knext/fiqa-pl-qrels couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/dtomal/.cache/huggingface/datasets/clarin-knext___fiqa-pl-qrels/default/0.0.0/11adceb9cbc24a6462532316290250b0afe91c4b (last modified on Fri Nov  1 13:47:36 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": "   query-id  corpus-id  score\n0         8     566392      1\n1         8      65404      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query-id</th>\n      <th>corpus-id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>566392</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>65404</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load QA dataset \n",
    "ds_qa = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "data_qa = ds_qa['test']\n",
    "df_qa = pd.DataFrame(data_qa)\n",
    "df_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69a5e77d2260dda",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:43.543517Z",
     "start_time": "2024-11-17T16:03:41.321890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  _id title                                               text\n0   0        Co jest uważane za wydatek służbowy w podróży ...\n1   4        Wydatki służbowe - ubezpieczenie samochodu pod...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td></td>\n      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td></td>\n      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Questions dataset \n",
    "data_queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "df_q = pd.DataFrame(data_queries['queries'])\n",
    "df_q.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447a663f6aae7bea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:43.580463Z",
     "start_time": "2024-11-17T16:03:43.544204Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "nlp = Polish()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cdedf30c98fa95f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.712893Z",
     "start_time": "2024-11-17T16:03:43.582662Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "all_tokens = []\n",
    "# tokenize and count words in corpus['texts'\n",
    "for doc in df_texts['text']:\n",
    "    doc_tokens = tokenizer(doc)\n",
    "    doc_tokens = [token.text for token in doc_tokens]\n",
    "    all_tokens.extend(doc_tokens)\n",
    "# Count\n",
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da56fb095c67cab5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.736163Z",
     "start_time": "2024-11-17T16:03:51.714250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('w', 156232), ('i', 120930), ('na', 113615), ('nie', 107751), ('z', 92365)]\n"
     ]
    }
   ],
   "source": [
    "# 5 most common tokens\n",
    "top_5 = token_counts.most_common(5)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc0537835d16e9e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.751020Z",
     "start_time": "2024-11-17T16:03:51.739589Z"
    }
   },
   "outputs": [],
   "source": [
    "token_counts = dict(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a42c4ddc1a2f92",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.802604Z",
     "start_time": "2024-11-17T16:03:51.752709Z"
    }
   },
   "outputs": [],
   "source": [
    "# distortion funtion\n",
    "def distort_word(word):\n",
    "    if len(word) == 0:\n",
    "        return word\n",
    "    \n",
    "    operation = random.choice(['remove', 'add', 'change']) \n",
    "\n",
    "    if operation == 'remove':\n",
    "        if len(word) > 1:  # remove one letter\n",
    "            char_index = random.randint(0, len(word) - 1)\n",
    "            word = word[:char_index] + word[char_index + 1:]\n",
    "\n",
    "    elif operation == 'add':\n",
    "        char_index = random.randint(0, len(word))\n",
    "        random_char = random.choice(string.ascii_lowercase)  # Add a random lowercase one letter\n",
    "        word = word[:char_index] + random_char + word[char_index:]\n",
    "\n",
    "    elif operation == 'change':\n",
    "        char_index = random.randint(0, len(word) - 1)\n",
    "        random_char = random.choice(string.ascii_lowercase)  # Change one letter to a random lowercase letter\n",
    "        word = word[:char_index] + random_char + word[char_index + 1:]\n",
    "\n",
    "    return word\n",
    "\n",
    "def distort_query(query):\n",
    "    words = query.split()  # Split the query into words\n",
    "    if not words:\n",
    "        return query\n",
    "\n",
    "    word_index = random.randint(0, len(words) - 1)\n",
    "    words[word_index] = distort_word(words[word_index])\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "#queries = [\"This is a sample query\", \"Another test case\", \"Distortion function example\"]\n",
    "#distorted_queries = distort_corpus(queries)\n",
    "#print(distorted_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef41f0a6d59d356",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.828832Z",
     "start_time": "2024-11-17T16:03:51.803613Z"
    }
   },
   "outputs": [],
   "source": [
    "df_q['distorted_query'] = df_q['text'].apply(distort_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f535c078c35ba44",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:51.835382Z",
     "start_time": "2024-11-17T16:03:51.829999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  _id title                                               text  \\\n0   0        Co jest uważane za wydatek służbowy w podróży ...   \n1   4        Wydatki służbowe - ubezpieczenie samochodu pod...   \n2   5                        Rozpoczęcie nowego biznesu online   \n\n                                     distorted_query  \n0  Co jest uważane za wydatek służbowy w odróży s...  \n1  Wydatki służbowe - ubezpieczenie samochodu pod...  \n2                  Rozpoczęcie nowego biznhsu online  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>text</th>\n      <th>distorted_query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td></td>\n      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n      <td>Co jest uważane za wydatek służbowy w odróży s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td></td>\n      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td></td>\n      <td>Rozpoczęcie nowego biznesu online</td>\n      <td>Rozpoczęcie nowego biznhsu online</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15139525c148dc6d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:52.140618Z",
     "start_time": "2024-11-17T16:03:51.836922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'node-1', 'cluster_name': 'my-application-cluster', 'cluster_uuid': 'gBI4PdSoQuCa8sMPxLY-yQ', 'version': {'number': '8.15.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '98adf7bf6bb69b66ab95b761c9e5aadb0bb059a3', 'build_date': '2024-09-19T10:06:03.564235954Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "# NDCG\n",
    "# es:\n",
    "es = Elasticsearch([\"http://elastics:password@localhost:9200\"], verify_certs=False)\n",
    "try:\n",
    "    resp = es.info()\n",
    "    print(resp)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9442b5e35b533885",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:52.143523Z",
     "start_time": "2024-11-17T16:03:52.141815Z"
    }
   },
   "outputs": [],
   "source": [
    "# index from previous lab:\n",
    "index_name = \"fiqa_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e383f5e8b282c3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:52.280208Z",
     "start_time": "2024-11-17T16:03:52.143991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully uploaded.\n"
     ]
    }
   ],
   "source": [
    "if es.count(index=index_name)['count'] == len(df_texts['text']):\n",
    "    print(\"Data successfully uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce452bfd49eda31",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:52.288826Z",
     "start_time": "2024-11-17T16:03:52.282881Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_dcg(scores):\n",
    "    return sum(score / np.log(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "\n",
    "def compute_ndcg(relevant_scores, retrieved_scores, k=5):\n",
    "    dcg = compute_dcg(retrieved_scores[:k]) # to sa te ktore zwrocil nasz 'model'\n",
    "    ideal_dcg = compute_dcg(sorted(relevant_scores, reverse=True)[:k]) # relevant uzywamy do idealnego dcg (idealne ulozenie odpowiedzi)\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "NDCG_SIZE = 10\n",
    "\n",
    "\n",
    "def search_and_compute_ndcg(index_name, analyzator_content, test_data, ndcg_size, query_column_name, fuzzy=False):\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    # obliczamy dla kazdej query dostepnej w testowym zbiorze danych\n",
    "    for index, row in test_data.iterrows():\n",
    "        # query id\n",
    "        query_id = row[\"query-id\"]\n",
    "        # query text\n",
    "        query = df_q[df_q['_id'] == str(query_id)][query_column_name].values[0]\n",
    "        # Wykonanie zapytania do Elasticsearch\n",
    "        if fuzzy is False:\n",
    "            search_query = {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        analyzator_content: query,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            search_query = {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    analyzator_content: {\n",
    "                        \"query\": query,\n",
    "                        \"fuzziness\": \"AUTO\"  # \"AUTO\", \"1\", \"2\", itp.\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "            \n",
    "        # bierzemy 5 pierwszych dopasowań od Elastic search (dostał query) zwraca nam 5 dokumentów\n",
    "        response = es.search(index=index_name, body=search_query, size=ndcg_size)\n",
    "        retrieved_docs = [hit[\"_id\"] for hit in response[\"hits\"][\"hits\"]] # id 5 dokumentow zwrocone przez ES\n",
    "        # Wszysktie A które pasuja do Q (z labelowanego dataset)\n",
    "        good_answers = df_qa[df_qa['query-id'] == int(query_id)]\n",
    "        # sortuje je po ich 'score', one i tak mają 1 ale na przyszlosc z lepszym datasetem zeby gralo bo tak sie realizuje IDCG\n",
    "        good_answers = good_answers.sort_values(by='score', ascending=False)\n",
    "        # Biore posortowane kolejne elementy z dobrymyim odpowiedziami, jesli nie ma ich (5) to uzupelniam 0 ami aby było zawsze 5 elementów - prawidlowe ndcg tak działa\n",
    "        relenvant_answears = list(good_answers['score'][:ndcg_size]) + [0] * (ndcg_size - len(good_answers)) # idealne odpowiedzi\n",
    "        # print(relenvant_answears) -> cos w stylu [1,1,0,0,0]\n",
    "        \n",
    "        \n",
    "        retrived_answears = [0 for _ in range(ndcg_size)] #otrzymane odpowiedzi\n",
    "        for idx, doc_found in enumerate(retrieved_docs):\n",
    "            if int(doc_found) in good_answers['corpus-id'].values:\n",
    "                retrived_answears[idx] = good_answers[good_answers['corpus-id'] == int(doc_found)]['score'].iloc[0]\n",
    "        \n",
    "        #print(retrived_answears) # -> cos w stylu [0,1,0,0,0]\n",
    "        ndcg = compute_ndcg(relenvant_answears, retrived_answears, k=5)\n",
    "        ndcg_scores.append(ndcg) # ndcg dla kazdego query sumujemy\n",
    "\n",
    "    # Zwracamy średnie NDCG dla wszystkich zapytań\n",
    "    return np.mean(ndcg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0d3a8cab93cab1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:03:52.292716Z",
     "start_time": "2024-11-17T16:03:52.289295Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_no_duplicates = df_qa.drop_duplicates(subset='query-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2638262978134e20",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:00.367241Z",
     "start_time": "2024-11-17T16:03:52.293210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla QA NIE zaszumione query (synonimy + lematyzacja): 0.1851291130797741\n"
     ]
    }
   ],
   "source": [
    "time_start_query = time.time()\n",
    "mean_ndcg_query = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates, NDCG_SIZE, query_column_name='text')\n",
    "time_end_query = time.time()\n",
    "execution_time_query = time_end_query - time_start_query\n",
    "print(\"Średnie NDCG dla QA NIE zaszumione query (synonimy + lematyzacja):\",mean_ndcg_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851607993b08029c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:07.885596Z",
     "start_time": "2024-11-17T16:04:00.372020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla QA zaszumione query (synonimy + lematyzacja): 0.16211935492018717\n"
     ]
    }
   ],
   "source": [
    "time_start_query_disto = time.time()\n",
    "mean_ndcg_distorted = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates, NDCG_SIZE, query_column_name='distorted_query')\n",
    "time_end_query_disto = time.time()\n",
    "execution_time_query_disto = time_end_query_disto - time_start_query_disto\n",
    "print(\"Średnie NDCG dla QA zaszumione query (synonimy + lematyzacja):\",mean_ndcg_distorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff556164d1760a07",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:07.890872Z",
     "start_time": "2024-11-17T16:04:07.887724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pierwszy wniosek - dla zaszumionych query (zaszumienie zgodnie z instrukcja - jedno slowo jedna litera) odrazu widzimy spadek sredniego NDCG z 0.18 na 0.16. W zasadzie zgodne jest to z intuicją. Zaszumiamy dane -> gorsze rezultaty, spodziewany wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eaf49fca29c77bd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:11.454395Z",
     "start_time": "2024-11-17T16:04:07.891957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    a\n1    a\n2    a\nName: 0, dtype: object"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Morfeusz\n",
    "# Niestety notebook jest wykonywany na komputerze Mac M3 i nie ma wsprcia morfeusza dla tej architektury procesora. Dlatego pobieram plik sgjp i z niego będę brać słowa\n",
    "#plik pobrany z oficjalnej storny morfeusza\n",
    "df_morfeusz = pd.read_csv(\n",
    "    \"sgjp-morfeusz.tab\",\n",
    "    sep=\"\\t\",           \n",
    "    encoding=\"utf-8\",    \n",
    "    comment=\"#\",\n",
    "    skiprows=30,\n",
    "    header=None      \n",
    ")\n",
    "\n",
    "correct_words = df_morfeusz[0]#\n",
    "correct_words.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "111e00b4fe65253e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:11.459915Z",
     "start_time": "2024-11-17T16:04:11.455502Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_incorrect_word_in_query(query, correct_words_list = correct_words.values):\n",
    "    for idx, word in enumerate(query.split()):\n",
    "        if word not in correct_words_list:\n",
    "            return idx, word\n",
    "def get_candidates_for_wrong_word(word):\n",
    "    letters = 'aąbcćdeęfghijklłmnńoópqrsśtuvwxyzźż'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def get_best_candidate(candidate_words, global_list=token_counts):\n",
    "    N = sum(global_list.values())\n",
    "    candidates_proba = []\n",
    "    for word in candidate_words:\n",
    "        candidates_proba.append([word, global_list.get(word, 0) / N])\n",
    "    return max(candidates_proba, key=lambda x: x[1])[0] # Here we take only word from (word, highest_proba)\n",
    "\n",
    "def correct_query(query):\n",
    "    out_word = find_incorrect_word_in_query(query)\n",
    "    if out_word is None:\n",
    "        return query\n",
    "    else:\n",
    "        idx, wrong_word = out_word[0], out_word[1]\n",
    "    candidates = get_candidates_for_wrong_word(wrong_word)\n",
    "    best_cand = get_best_candidate(candidates)\n",
    "    \n",
    "    query_words = query.split()\n",
    "    if 0 <= idx < len(query_words):\n",
    "        query_words[idx] = best_cand\n",
    "    corrected_query = ' '.join(query_words)\n",
    "    return corrected_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a07ba88ec40f69",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:04:12.167772Z",
     "start_time": "2024-11-17T16:04:11.460568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Query:\n",
      "Co jest uważane za wydatek służbowy w odróży służbowej?\n",
      "## Wrong word:\n",
      "odróży\n",
      "## 5 candidates:\n",
      "['odhróży', 'odróżyś', 'odróżyp', 'oderóży', 'lodróży']\n",
      "## najlepszy kandydat\n",
      "podróży\n",
      "## poprawiona query\n",
      "Co jest uważane za wydatek służbowy w podróży służbowej?\n"
     ]
    }
   ],
   "source": [
    "print(\"## Query:\")\n",
    "query = df_q['distorted_query'].iloc[0]\n",
    "print(query)\n",
    "print(\"## Wrong word:\")\n",
    "wrong_word = find_incorrect_word_in_query(query)[1]\n",
    "print(wrong_word)\n",
    "print(\"## 5 candidates:\")\n",
    "cands = get_candidates_for_wrong_word(wrong_word)\n",
    "print(list(cands)[:5])\n",
    "print(\"## najlepszy kandydat\")\n",
    "best_word = get_best_candidate(cands, token_counts)\n",
    "print(best_word)\n",
    "print(\"## poprawiona query\")\n",
    "print(correct_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6d890093d7d53d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:14:56.716350Z",
     "start_time": "2024-11-17T16:04:12.168382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spelling Correction with my method:\n",
    "df_q['corrected_query'] = df_q['distorted_query'].apply(correct_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c983df56d58a48b1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:01.977021Z",
     "start_time": "2024-11-17T16:14:56.719131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla QA zaszumione + poprawione (synonimy + lematyzacja): 0.16453810883289954\n"
     ]
    }
   ],
   "source": [
    "time_start_query_corrected_leven = time.time()\n",
    "mean_ndcg_corrected_leven = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates, NDCG_SIZE, query_column_name='corrected_query')\n",
    "time_end_query_corrected_leven = time.time()\n",
    "execution_time_query_corrected_leven = time_end_query_corrected_leven - time_start_query_corrected_leven\n",
    "print(\"Średnie NDCG dla QA zaszumione + poprawione (synonimy + lematyzacja):\",mean_ndcg_corrected_leven)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb558ac6fcea7063",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wyniki lepsze niż z zaszumionym query, gorsze niz przed zaszumieniem. Chyba tak to powinno wyglądać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91082428a0563d6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.442856Z",
     "start_time": "2024-11-17T16:15:01.979495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla QA zaszumione + poprawione (synonimy + lematyzacja): 0.1381718913929553\n"
     ]
    }
   ],
   "source": [
    "time_start_query_corrected_fuzzy = time.time()\n",
    "mean_ndcg_corrected_fuzzy = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates, NDCG_SIZE, query_column_name='distorted_query', fuzzy=True)\n",
    "time_end_query_corrected_fuzzy = time.time()\n",
    "execution_time_query_corrected_fuzzy = time_end_query_corrected_fuzzy - time_start_query_corrected_fuzzy\n",
    "print(\"Średnie NDCG dla QA zaszumione + poprawione (synonimy + lematyzacja):\",mean_ndcg_corrected_fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c91c40b2ddb655a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.452487Z",
     "start_time": "2024-11-17T16:15:22.445632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG i performance metod:\n",
      "Query -----------------------> 8.070882081985474 [s] 0.1851291130797741 NDCG@10\n",
      "Distorted Query -------------> 7.503586769104004 [s] 0.16211935492018717 NDCG@10\n",
      "Levensthein corrected Query -> 5.251115798950195 [s] 0.16453810883289954 NDCG@10\n",
      "Fuzzy match corrected Query -> 20.454473972320557 [s] 0.1381718913929553 NDCG@10\n"
     ]
    }
   ],
   "source": [
    "print(\"NDCG i performance metod:\")\n",
    "print(f\"Query -----------------------> {execution_time_query} [s] {mean_ndcg_query} NDCG@10\")\n",
    "print(f\"Distorted Query -------------> {execution_time_query_disto} [s] {mean_ndcg_distorted} NDCG@10\")\n",
    "print(f\"Levensthein corrected Query -> {execution_time_query_corrected_leven} [s] {mean_ndcg_corrected_leven} NDCG@10\")\n",
    "print(f\"Fuzzy match corrected Query -> {execution_time_query_corrected_fuzzy} [s] {mean_ndcg_corrected_fuzzy} NDCG@10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecd7b980729fd729",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.458948Z",
     "start_time": "2024-11-17T16:15:22.453307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       8\n2      15\n3      18\n4      26\n6      34\n7      42\n10     56\n11     68\n12     89\n18     90\n19     94\n20     98\n22    104\n24    106\n25    109\n26    475\n27    503\n28    504\n31    515\n32    529\n33    547\n35    549\n36    559\n37    570\n38    585\n40    588\n42    594\n44    603\n45    604\n48    620\nName: query-id, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_30_query = qa_no_duplicates['query-id'].iloc[:30]\n",
    "first_30_query = first_30_query.astype(str)\n",
    "first_30_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83727821bac5eba0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.475732Z",
     "start_time": "2024-11-17T16:15:22.459575Z"
    }
   },
   "outputs": [],
   "source": [
    "df_q['_id'] = df_q['_id'].astype(str)  \n",
    "df_q30 = df_q[df_q['_id'].isin(first_30_query)]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "301326899e9441dc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.478486Z",
     "start_time": "2024-11-17T16:15:22.476492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query do bielika to było:\n",
    "# Dla kazdego z tych 30 pytan, popraw je i zwroc poprawiona wersje: \n",
    "# Bielki zwrócił:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aea56322b8bf6e32",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:22.482653Z",
     "start_time": "2024-11-17T16:15:22.479443Z"
    }
   },
   "outputs": [],
   "source": [
    "bielik_q = [\n",
    "\"Jakie są opcje pracodawcy przy zakładaniu planu 401(k) dla pracowników?\",\n",
    "\"Czy sprzedawca detaliczny powinien czytać dokumenty SEC?\",\n",
    "\"Czy brak odcinka wypłaty jako zabezpieczenia może spowodować odrzucenie wniosku o pożyczkę edukacyjną?\",\n",
    "\"Czy mądre jest posiadanie wielu rachunków bieżących w różnych bankach?\",\n",
    "\"Jakie są identyfikacje dotyczące kwoty podlegającej odliczeniu dla małych firm?\",\n",
    "\"Jak dokonać przelewu 401(k) po zamknięciu firmy?\",\n",
    "\"Czy jeden EIN może prowadzić działalność pod wieloma nazwami firm?\",\n",
    "\"Jak rozliczyć zarobione i wydane pieniądze przed założeniem firmowych kont bankowych?\",\n",
    "\"Czy podążanie za guru inwestycyjnym jest dobrym pomysłem?\",\n",
    "\"Czy przedsiębiorca może zatrudnić samozatrudnionego właściciela firmy?\",\n",
    "\"Jakie są różnice między składaniem osobistego zeznania 1099 a NS-Corp biznesowym?\",\n",
    "\"Czy jest powód, aby inwestować w obligacje o rentowności 0%?\",\n",
    "\"Jakie są podejścia do wyceny małej firmy?\",\n",
    "\"Czy warto założyć firmę jednoosobową czy LLC?\",\n",
    "\"Jak ubiegać się o kredyt biznesowy i go otrzymać?\",\n",
    "\"Czy potrzebuję nowego numeru EIN, jeśli zatrudniam pracowników do mojej LLC?\",\n",
    "\"Jak mogę wpłacić czek wystawiony na moją firmę na moje konto osobiste?\",\n",
    "\"Jak mogę zarobić 250 000 $ z handlu, inwestowania lub biznesu w ciągu 5 lat?\",\n",
    "\"Jakie są preferencje dotyczące prywatności danych kredytowych?\",\n",
    "\"Gdzie mogę poprosić ACH Direct Debit o środki z mojego osobistego konta bankowego?\",\n",
    "\"Co się dzieje po zakwestionowaniu pozornie fałszywego obciążenia karty kredytowej?\",\n",
    "\"Jakie są tajniki zakupu sprzętu do pisania jako wydatki biznesowe w firmie domowej?\",\n",
    "\"Co zrobić, gdy mam dużo przepływów pieniężnych, ale zły kredyt?\",\n",
    "\"Czy instytucja finansowa może wymagać podziału członka LLC na jednego członka?\",\n",
    "\"Czy istnieje kwota w dolarach, która po dodaniu podatku od sprzedaży w stanie Massachusetts wynosi dokładnie 200 USD?\",\n",
    "\"Jak działa inwestowanie/biznes z cudzymi pieniędzmi?\",\n",
    "\"Czy mogę wysłać przekaz pieniężny z USPS jako firma?\",\n",
    "\"Jak zdeponować czek wystawiony na współpracownika w mojej firmie na moje konto firmowe?\",\n",
    "\"Jaki procent mojej firmy powinienem mieć, jeśli tylko odkładam pieniądze?\",\n",
    "\"Czy mogę wykorzystać punkty kart kredytowych do opłacania kosztów prowadzenia działalności, które można odliczyć od podatku?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1061d4b5e080c3d6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:23:29.474370Z",
     "start_time": "2024-11-17T16:23:29.443028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      _id title                                               text  \\\n6024  570        Opcje pracodawcy przy zakładaniu 401k dla prac...   \n6026  594        Czy sprzedawca detaliczny powinien zawracać so...   \n6049  603        Czy wniosek o pożyczkę edukacyjną zostanie odr...   \n\n                                        distorted_query  \\\n6024  Opcje pracodawcy przy zakładani 401k dla praco...   \n6026  Czy sparzedawca detaliczny powinien zawracać s...   \n6049  Czy wniosek o pożyczkę edukacyjną zostanie odr...   \n\n                                        corrected_query  \\\n6024  opcje pracodawcy przy zakładani 401k dla praco...   \n6026  czy sparzedawca detaliczny powinien zawracać s...   \n6049  czy wniosek o pożyczkę edukacyjną zostanie odr...   \n\n                                               bielik_q  \n6024  Jakie są opcje pracodawcy przy zakładaniu plan...  \n6026  Czy sprzedawca detaliczny powinien czytać doku...  \n6049  Czy brak odcinka wypłaty jako zabezpieczenia m...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>text</th>\n      <th>distorted_query</th>\n      <th>corrected_query</th>\n      <th>bielik_q</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6024</th>\n      <td>570</td>\n      <td></td>\n      <td>Opcje pracodawcy przy zakładaniu 401k dla prac...</td>\n      <td>Opcje pracodawcy przy zakładani 401k dla praco...</td>\n      <td>opcje pracodawcy przy zakładani 401k dla praco...</td>\n      <td>Jakie są opcje pracodawcy przy zakładaniu plan...</td>\n    </tr>\n    <tr>\n      <th>6026</th>\n      <td>594</td>\n      <td></td>\n      <td>Czy sprzedawca detaliczny powinien zawracać so...</td>\n      <td>Czy sparzedawca detaliczny powinien zawracać s...</td>\n      <td>czy sparzedawca detaliczny powinien zawracać s...</td>\n      <td>Czy sprzedawca detaliczny powinien czytać doku...</td>\n    </tr>\n    <tr>\n      <th>6049</th>\n      <td>603</td>\n      <td></td>\n      <td>Czy wniosek o pożyczkę edukacyjną zostanie odr...</td>\n      <td>Czy wniosek o pożyczkę edukacyjną zostanie odr...</td>\n      <td>czy wniosek o pożyczkę edukacyjną zostanie odr...</td>\n      <td>Czy brak odcinka wypłaty jako zabezpieczenia m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q30.loc[:, \"bielik_q\"] = bielik_q\n",
    "df_q30.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13c7dd91e9c7b93d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:23:33.252582Z",
     "start_time": "2024-11-17T16:23:32.782046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla 30 QA zaszumione + poprawione levenstheinem: 0.11058431217693115\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg_30corrected_query = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates[:30], NDCG_SIZE, query_column_name='corrected_query')\n",
    "print(\"Średnie NDCG dla 30 QA zaszumione + poprawione levenstheinem:\",mean_ndcg_30corrected_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8ccf5e2033e8dd9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:23:34.861650Z",
     "start_time": "2024-11-17T16:23:34.576464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnie NDCG dla 30 QA zaszumione + poprawione LLM: 0.1672594186935333\n"
     ]
    }
   ],
   "source": [
    "df_q = df_q30\n",
    "mean_ndcg_30corrected_llm = search_and_compute_ndcg(index_name, 'content_synon', qa_no_duplicates[:30], NDCG_SIZE, query_column_name='bielik_q')\n",
    "print(\"Średnie NDCG dla 30 QA zaszumione + poprawione LLM:\",mean_ndcg_30corrected_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0278245d4905338",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Wnioski\n",
    "Bardzo ciekawe i fajne ćwiczenie. \n",
    "'The distribution of word in the corpus' - Niestety nie rozumiem co to znaczy? Co tutaj powinniśmy zrobić? Wypisać liste które słowo jak często występuje? Nie rozumiem.\n",
    "Dalsze wnioski:\n",
    "Opłacało sie przesiedzieć cały wieczór nad popdzenim i dobrze zaimplementować NDCG bo teraz można było je ponownie użyć. Początkowo zaimplementowałem word correction jako obliczanie odleglosci levenstheina: oblicz odleglosc blednego slowa od calego slownika, wybierz te slowa ktore maja najmniejsze i wybierz to które ma najwieksze prawdopodobieństwo (wystąpiło najczęściej w korpusie) - Działało ok. Jednak jest to bardzo nieefektywne rozwiązanie bo trwa bardzo długo i pewnie nie zdążyło by się to obliczyć do terminu oddania. Następnie znalazłem podejście któ®ego używa się w praktyce, szukamy 'kandydatów' w odległości 1 i bierzemy tego któ®y najczęściej wystepował w korpusie. Tutaj już ok. Zdążyło się poprawić w rozsądnym czasie.\n",
    "\n",
    "\n",
    "Podsumowanie Performance:\n",
    "dla całego korpusu:\n",
    "najlepszy wynik (najwyzsze NDCG@10) dla nie zaszumionych query - dość oczywiste. Co ciekaw dla mnie, z moich badań wynikneło, że koreka levenstheina działała lepiej i dała lepsze wyniki niż fuzzy match z ElasticSearch. Dużo szybciej (tutaj trzeba mieć na uwadze ze jednak poprawienie datasetu trwało długo jednak już wyszukiwanie szybko) i dokładniej niż gotowe rozwiązanie fuzzy. Najgorsze wyniki dla distorted query - też dośc oczywiste, jeśli mamy większy szum -> gorsze wyniki.\n",
    "Fuzzy match, nie wymagało jednak implementacji praktycznie niczego, wykonywało się dłużej  , jednak bez preprocessingu. Moim zdaniem jesli zbiór danych nie będzie się zmieniał warto zaimplementować korekcję z wykorzystaniem metryki levenshteina i 'poprawic' zbior danych raz, zeby pozniej wnioskowac szybciej i dokladnie, jesli jednak zbior danych zmienia sie lub nie mamy czasu to fuzzy match powinno byc wystarczające.\n",
    "\n",
    "NDCG@10 na 30 pierwszych query:\n",
    "Tutaj LLM (bielik) znacznie lepiej poprawił query niz metoda z levenshteinem i uzyskał wyższe NDCG. Jest to bardzo ciekawy wynik, bo darmy LLM dobrze sobie radzi z takim zadaniem i wyniki są dobre. Jednak mimo 'prośby' bielika o zmiane jedynie jednego słowa, zmieniał on nieraz więcej słów. Może to być wada i zaleta, zaleta bo lepiej 'rozumie' kontekst i może poprawić dokładniej. Wada bo zmieniamy orgyinalne Query.\n",
    "ćwiczenie ciekawe, pozwoliło zrozumieć metryke levenstheina, jak działa 'did you mean?' 'spell correction' oraz utrwalić wiedzę o NDCG i jak można ewaluować zadania typu - Question - Answear. Przy dobrze zaimplementowanym poprzednim ćwiczeniu nie wymagało aż tak wielkiego nakładu czasu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12666eca3d9369c7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T16:15:23.033774Z",
     "start_time": "2024-11-17T16:15:23.032404Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
